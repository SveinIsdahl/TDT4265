{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision.ops import generalized_box_iou\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.image_filenames = [f for f in os.listdir(image_dir) if f.endswith('.PNG')]\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((800, 1066)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.image_filenames[idx]\n",
    "        label_filename = img_filename.replace('.PNG', '.txt')\n",
    "\n",
    "        image = Image.open(os.path.join(self.image_dir, img_filename)).convert(\"RGB\")\n",
    "        w, h = image.size\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        with open(os.path.join(self.label_dir, label_filename), 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                class_id = int(parts[0])\n",
    "                x, y, bw, bh = map(float, parts[1:])\n",
    "                labels.append(class_id)\n",
    "                boxes.append([x, y, bw, bh])\n",
    "\n",
    "        image_tensor = self.transform(image)\n",
    "        target = {\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "            \"boxes\": torch.tensor(boxes, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "        return image_tensor, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETR(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1, hidden_dim=256, nheads=8,\n",
    "                 num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.backbone = resnet50(pretrained=True)\n",
    "        del self.backbone.fc \n",
    "        \n",
    "        self.conv = nn.Conv2d(2048, hidden_dim, 1)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "        self.linear_class = nn.Linear(hidden_dim, num_classes + 1)\n",
    "        self.linear_bbox = nn.Linear(hidden_dim, 4)\n",
    "        \n",
    "        self.query_pos = nn.Parameter(torch.rand(100, hidden_dim))\n",
    "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "        self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "\n",
    "    def forward(self, inputs): \n",
    "        x = self.backbone.conv1(inputs)    \n",
    "        x = self.backbone.bn1(x)           \n",
    "        x = self.backbone.relu(x)          \n",
    "        x = self.backbone.maxpool(x)       \n",
    "\n",
    "        x = self.backbone.layer1(x)        \n",
    "        x = self.backbone.layer2(x)        \n",
    "        x = self.backbone.layer3(x)        \n",
    "        x = self.backbone.layer4(x)        \n",
    "\n",
    "        h = self.conv(x)                   \n",
    "\n",
    "        H, W = h.shape[-2:]\n",
    "        pos = torch.cat([\n",
    "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1) \n",
    "\n",
    "        src = pos + 0.1 * h.flatten(2).permute(2, 0, 1)  \n",
    "        batch_size = inputs.shape[0]\n",
    "        target = self.query_pos.unsqueeze(1).repeat(1, batch_size, 1)  \n",
    "\n",
    "        \n",
    "        h = self.transformer(src, target).transpose(0, 1) \n",
    "\n",
    "        linear_cls = self.linear_class(h)        \n",
    "        linear_bbx = self.linear_bbox(h).sigmoid()  \n",
    "        \n",
    "        \n",
    "        return {'pred_logits': linear_cls,  \n",
    "                'pred_boxes': linear_bbx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boxes from [cx, cy, w, h] to [x1, y1, x2, y2]\n",
    "def box_cxcywh_to_xyxy(boxes):\n",
    "    x_c, y_c, w, h = boxes.unbind(-1)\n",
    "    return torch.stack([x_c - 0.5 * w, y_c - 0.5 * h,\n",
    "                        x_c + 0.5 * w, y_c + 0.5 * h], dim=-1)\n",
    "\n",
    "# Compute cost matrix for matching\n",
    "def compute_cost(pred_logits, pred_boxes, tgt_labels, tgt_boxes):\n",
    "    # Classification cost (negative log-likelihood)\n",
    "    prob = pred_logits.softmax(-1)\n",
    "    cost_class = -prob[:, tgt_labels]\n",
    "\n",
    "    # L1 cost\n",
    "    cost_bbox = torch.cdist(pred_boxes, tgt_boxes, p=1)\n",
    "\n",
    "    # IoU cost (1 - GIoU)\n",
    "    giou = generalized_box_iou(\n",
    "        box_cxcywh_to_xyxy(pred_boxes),\n",
    "        box_cxcywh_to_xyxy(tgt_boxes)\n",
    "    )\n",
    "    cost_giou = 1 - giou\n",
    "\n",
    "    return cost_class + cost_bbox + cost_giou\n",
    "\n",
    "# Hungarian matching\n",
    "def match(pred_logits, pred_boxes, targets):\n",
    "    indices = []\n",
    "    for b in range(pred_logits.shape[0]):\n",
    "        cost = compute_cost(\n",
    "            pred_logits[b], pred_boxes[b],\n",
    "            targets[b]['labels'], targets[b]['boxes']\n",
    "        ).detach().cpu().numpy()\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "        indices.append((row_ind, col_ind))\n",
    "    return indices\n",
    "\n",
    "# Loss function\n",
    "class DetrLoss(nn.Module):\n",
    "    def __init__(self, class_weight=1, bbox_weight=5, giou_weight=2):\n",
    "        super().__init__()\n",
    "        self.class_weight = class_weight\n",
    "        self.bbox_weight = bbox_weight\n",
    "        self.giou_weight = giou_weight\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        pred_logits = outputs['pred_logits']  # [B, 100, num_classes+1]\n",
    "        pred_boxes = outputs['pred_boxes']    # [B, 100, 4]\n",
    "\n",
    "        indices = match(pred_logits, pred_boxes, targets)\n",
    "\n",
    "        loss_cls, loss_bbox, loss_giou = 0, 0, 0\n",
    "\n",
    "        for b, (src_idx, tgt_idx) in enumerate(indices):\n",
    "            src_logits = pred_logits[b][src_idx]\n",
    "            tgt_labels = targets[b]['labels'][tgt_idx]\n",
    "            loss_cls += F.cross_entropy(src_logits, tgt_labels)\n",
    "\n",
    "            src_boxes = pred_boxes[b][src_idx]\n",
    "            tgt_boxes = targets[b]['boxes'][tgt_idx]\n",
    "\n",
    "            loss_bbox += F.l1_loss(src_boxes, tgt_boxes)\n",
    "\n",
    "            giou = generalized_box_iou(\n",
    "                box_cxcywh_to_xyxy(src_boxes),\n",
    "                box_cxcywh_to_xyxy(tgt_boxes)\n",
    "            )\n",
    "            loss_giou += 1 - giou.diag().mean()\n",
    "\n",
    "        num_boxes = sum(len(t['labels']) for t in targets)\n",
    "        loss_dict = {\n",
    "            'loss_cls': loss_cls / num_boxes,\n",
    "            'loss_bbox': loss_bbox / num_boxes,\n",
    "            'loss_giou': loss_giou / num_boxes\n",
    "        }\n",
    "\n",
    "        total_loss = (\n",
    "            self.class_weight * loss_dict['loss_cls'] +\n",
    "            self.bbox_weight * loss_dict['loss_bbox'] +\n",
    "            self.giou_weight * loss_dict['loss_giou']\n",
    "        )\n",
    "\n",
    "        loss_dict['total_loss'] = total_loss\n",
    "        return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = YoloDataset(\"/datasets/tdt4265/ad/open/Poles/rgb/images/train\", \"/datasets/tdt4265/ad/open/Poles/rgb/labels/train\")\n",
    "for images, targets in dataset:\n",
    "    print(targets['boxes'])\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "model = DETR().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = DetrLoss()\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    dataloader_tqdm = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    \n",
    "    for images, targets in dataloader_tqdm:\n",
    "\n",
    "        images = torch.stack(images).to(device)\n",
    "        \n",
    "        \n",
    "        targets = [\n",
    "            {\n",
    "                \"labels\": t[\"labels\"].to(device),\n",
    "                \"boxes\": t[\"boxes\"].to(device)\n",
    "            }\n",
    "            for t in targets\n",
    "        ]\n",
    "        \n",
    "        outputs = model(images)\n",
    "\n",
    "        loss_dict = loss_fn(outputs, targets)\n",
    "        loss = loss_dict['total_loss']\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        dataloader_tqdm.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "im_num = 30\n",
    "\n",
    "image_path = \"/datasets/tdt4265/ad/open/Poles/rgb/images/valid\"\n",
    "\n",
    "images = [str(p) for p in Path(image_path).glob(\"*.PNG\")]\n",
    "\n",
    "image = Image.open(images[im_num]).convert(\"RGB\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((800, 1066)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "image_tensor = transform(image).unsqueeze(0).to(device) \n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)\n",
    "\n",
    "logits = outputs['pred_logits'][0]     \n",
    "boxes = outputs['pred_boxes'][0]      \n",
    "probs = logits.softmax(-1)\n",
    "scores, labels = probs[..., :-1].max(-1) \n",
    "\n",
    "threshold = 0.7 \n",
    "keep = scores > threshold\n",
    "\n",
    "boxes = boxes[keep]\n",
    "labels = labels[keep]\n",
    "scores = scores[keep]\n",
    "\n",
    "\n",
    "\n",
    "def box_cxcywh_to_xyxy(box):\n",
    "    x_c, y_c, w, h = box.unbind(-1)\n",
    "    return torch.stack([\n",
    "        x_c - 0.5 * w, y_c - 0.5 * h,\n",
    "        x_c + 0.5 * w, y_c + 0.5 * h\n",
    "    ], dim=-1)\n",
    "\n",
    "w, h = image.size\n",
    "\n",
    "boxes = box_cxcywh_to_xyxy(boxes)\n",
    "boxes *= torch.tensor([w, h, w, h], device=boxes.device)\n",
    "\n",
    "def plot_detections(image, boxes, scores, labels):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for box, score in zip(boxes, scores):\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                                 linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1, f'{score:.2f}', fontsize=10, color='white',\n",
    "                bbox=dict(facecolor='red', edgecolor='none', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_detections(image, boxes, scores, labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
