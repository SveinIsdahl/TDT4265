{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b15433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from effdet.efficientdet import HeadNet\n",
    "from timm.utils import AverageMeter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c78779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODetectionPaddedDataset(Dataset):\n",
    "    def __init__(self, images_dir, annotation_path):\n",
    "        self.images_dir = images_dir\n",
    "        self.coco = COCO(annotation_path)\n",
    "        self.image_ids = list(self.coco.imgs.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def pad_to_square(self, image, target):\n",
    "        w, h = image.size  # original size (1024, 128)\n",
    "        max_dim = max(w, h)  # 1024\n",
    "\n",
    "        # Compute padding (left, top, right, bottom)\n",
    "        pad_left = 0\n",
    "        pad_top = (max_dim - h) // 2\n",
    "        pad_right = 0\n",
    "        pad_bottom = max_dim - h - pad_top\n",
    "\n",
    "        # Apply padding to image\n",
    "        image = TF.pad(image, (pad_left, pad_top, pad_right, pad_bottom), fill=0)\n",
    "\n",
    "        # Apply same to boxes\n",
    "        boxes = target['boxes']\n",
    "        boxes[:, 1] += pad_top\n",
    "        boxes[:, 3] += pad_top\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coco = self.coco\n",
    "        image_id = self.image_ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=image_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Load image\n",
    "        img_info = coco.loadImgs(image_id)[0]\n",
    "        img_path = os.path.join(self.images_dir, img_info['file_name'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Load boxes and labels\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in anns:\n",
    "            if 'bbox' in ann:\n",
    "                x, y, w, h = ann['bbox']\n",
    "                boxes.append([x, y, x + w, y + h])\n",
    "                labels.append(0)  # Only one class â†’ label = 0\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([image_id])\n",
    "        }\n",
    "\n",
    "        # Pad image + boxes\n",
    "        image, target = self.pad_to_square(image, target)\n",
    "\n",
    "        # Normalize\n",
    "        image = TF.to_tensor(image)\n",
    "        image = TF.normalize(image, mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataset = COCODetectionPaddedDataset(\n",
    "    images_dir='./lidar_dataset_links/train/images',\n",
    "    annotation_path='lidar_train_coco.json'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "\n",
    "val_dataset = COCODetectionPaddedDataset(\n",
    "    images_dir='./lidar_dataset_links/valid/images',\n",
    "    annotation_path='lidar_valid_coco.json'\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807720e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 1\n",
    "epochs = 5\n",
    "batch_size = 5\n",
    "img_size = (1024, 1024)\n",
    "\n",
    "# --- Model creation ---\n",
    "config = get_efficientdet_config('tf_efficientdet_d2')\n",
    "config.num_classes = num_classes\n",
    "config.image_size = img_size\n",
    "config.norm_kwargs = dict(eps=0.001, momentum=0.01)\n",
    "\n",
    "net = EfficientDet(config, pretrained_backbone=True)\n",
    "net.class_net = HeadNet(config, num_outputs=num_classes)\n",
    "model = DetBenchTrain(net, config)\n",
    "model.to(device)\n",
    "\n",
    "# --- Optimizer ---\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# --- Training loop ---\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    for images, targets in train_loader:  # From your custom dataset\n",
    "        images = torch.stack([img.to(device) for img in images])\n",
    "\n",
    "        # Move target boxes and labels to device\n",
    "        boxes = [t['boxes'].to(device) for t in targets]\n",
    "        labels = [t['labels'].to(device) for t in targets]\n",
    "        targets_dict = {'bbox': boxes, 'cls': labels}\n",
    "\n",
    "        # EfficientDet expects list of dicts with 'boxes' and 'labels'\n",
    "        loss_dict = model(images, targets_dict)\n",
    "        loss = sum(loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_meter.update(loss.item(), len(images))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss_meter.avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aeb574",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"efficientdet_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"efficientdet_model.pth\",weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def run_inference(model, dataloader):\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    for images, targets in tqdm(dataloader):\n",
    "        images = torch.stack([img.to('cuda') for img in images])\n",
    "        image_ids = [t['image_id'].item() for t in targets]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "\n",
    "        for i, output in enumerate(outputs):\n",
    "            output = output.cpu()\n",
    "            boxes = output[:, :4]\n",
    "            scores = output[:, 4]\n",
    "            labels = output[:, 5].int()\n",
    "\n",
    "            results.append({\n",
    "                'image_id': image_ids[i],\n",
    "                'boxes': boxes,\n",
    "                'scores': scores,\n",
    "                'labels': labels\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import json\n",
    "\n",
    "\n",
    "def convert_to_coco(results, score_threshold=0.05):\n",
    "    coco_results = []\n",
    "    pad_top = 448  \n",
    "\n",
    "    for res in results:\n",
    "        for box, score, label in zip(res['boxes'], res['scores'], res['labels']):\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "\n",
    "            y1 -= pad_top\n",
    "            y2 -= pad_top\n",
    "\n",
    "            y1 = max(0, y1)\n",
    "            y2 = min(128, y2)\n",
    "\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "\n",
    "            if score >= score_threshold and width > 1 and height > 1:\n",
    "                coco_results.append({\n",
    "                    'image_id': int(res['image_id']),\n",
    "                    'category_id': int(label),  \n",
    "                    'bbox': [x1, y1, width, height],\n",
    "                    'score': float(score)\n",
    "                })\n",
    "    return coco_results\n",
    "\n",
    "\n",
    "def evaluate_coco(gt_annotations_file, predictions):\n",
    "    json_filename = 'predictionsNOOB.json'\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(predictions, f)\n",
    "\n",
    "    coco_gt = COCO(gt_annotations_file)\n",
    "    coco_dt = coco_gt.loadRes(json_filename)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from effdet import DetBenchPredict\n",
    "\n",
    "\n",
    "eval_model = DetBenchPredict(model.model).to(device)\n",
    "eval_model.eval()\n",
    "val_results = run_inference(eval_model, val_loader)\n",
    "coco_results = convert_to_coco(val_results,0.1)\n",
    "evaluate_coco('valid_coco.json', coco_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_gt = COCO('valid_coco copy.json')\n",
    "coco_dt = coco_gt.loadRes('predictionsNOOB.json')\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
